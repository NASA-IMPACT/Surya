{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Solar Wind Speed Forecasting Tutorial for Beginners 🌞💨\n",
        "\n",
        "This notebook will guide you through running Solar Wind speed forecasting using the Surya model. \n",
        "\n",
        "## What you'll learn:\n",
        "- How to load a pre-trained model for solar wind speed prediction\n",
        "- How to run inference on solar data\n",
        "- How to interpret regression forecasting results\n",
        "- Understanding continuous predictions vs binary classification\n",
        "\n",
        "## Prerequisites:\n",
        "- Make sure you're in the correct directory: `downstream_examples/solar_wind_forcasting/`\n",
        "- Ensure all required packages are installed (torch, yaml, matplotlib, numpy, etc.)\n",
        "\n",
        "Let's get started! 🚀\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/.venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All imports successful!\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "import numpy as np\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "# Import functions from our inference script\n",
        "from infer import (\n",
        "    run_inference,\n",
        ")\n",
        "\n",
        "# Import from surya\n",
        "from surya.utils.data import build_scalers\n",
        "from surya.utils.distributed import set_global_seed\n",
        "\n",
        "print(\"✅ All imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Download Pre-trained Model Weights\n",
        "The model weights will be downloaded automatically from Hugging Face.\n",
        "This may take a few minutes the first time you run the code.\n",
        "\n",
        "For downloading the dataset (if not already present locally):\n",
        "- If the cell below fails, try running the provided shell script directly in the terminal.\n",
        "- Sometimes the download may fail due to network or server issues—if that happens, simply re-run the script a few times until it completes successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Checking assets directory at: /nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets\n",
            "==> Downloading dataset 'nasa-ibm-ai4science/Surya-bench-solarwind' to '/nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets/Surya-bench-solarwind'\n",
            "Fetching 7 files: 100%|██████████████████████████| 7/7 [00:00<00:00, 426.70it/s]\n",
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets/Surya-bench-solarwind\n",
            "Fetching 1 files: 100%|██████████████████████████| 1/1 [00:00<00:00, 106.09it/s]\n",
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets\n",
            "Fetching 19 files: 100%|███████████████████████| 19/19 [00:00<00:00, 456.41it/s]\n",
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets\n",
            "✓ Done. Files are in: /nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets/Surya-bench-solarwind\n"
          ]
        }
      ],
      "source": [
        "!sh download_data.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Set Up Configuration\n",
        "\n",
        "We need to load the configuration file that contains all the model and data parameters. Make sure you have a `config.yaml` file in your current directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📋 Loading configuration...\n",
            "✅ Configuration loaded successfully!\n",
            "Model type: spectformer\n",
            "Data precision: torch.float32\n"
          ]
        }
      ],
      "source": [
        "# Configuration paths - modify these if your files are in different locations\n",
        "config_path = \"./config_infer.yaml\"\n",
        "checkpoint_path = \"./assets/solar_wind_weights.pth\"\n",
        "output_dir = \"./inference_results\"\n",
        "\n",
        "# Set global seed for reproducibility\n",
        "set_global_seed(42)\n",
        "\n",
        "# Load configuration\n",
        "print(\"📋 Loading configuration...\")\n",
        "try:\n",
        "    config = yaml.safe_load(open(config_path, \"r\"))\n",
        "    config[\"data\"][\"scalers\"] = yaml.safe_load(open(config[\"data\"][\"scalers_path\"], \"r\"))\n",
        "    print(\"✅ Configuration loaded successfully!\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"❌ Error: {e}\")\n",
        "    print(\"Make sure config.yaml exists in your current directory\")\n",
        "    raise\n",
        "\n",
        "# Set data type (float precision)\n",
        "if config[\"dtype\"] == \"float16\":\n",
        "    config[\"dtype\"] = torch.float16\n",
        "elif config[\"dtype\"] == \"bfloat16\":\n",
        "    config[\"dtype\"] = torch.bfloat16\n",
        "elif config[\"dtype\"] == \"float32\":\n",
        "    config[\"dtype\"] = torch.float32\n",
        "else:\n",
        "    raise NotImplementedError(\"Please choose from [float16,bfloat16,float32]\")\n",
        "\n",
        "print(f\"Model type: {config['model']['model_type']}\")\n",
        "print(f\"Data precision: {config['dtype']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 4: Set Up Device (GPU/CPU)\n",
        "\n",
        "Let's determine whether to use GPU or CPU for inference. GPU is much faster if available!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🐌 Using CPU (this will be slower)\n",
            "💡 Tip: Consider using a machine with GPU for faster inference\n"
          ]
        }
      ],
      "source": [
        "# Set device - automatically use GPU if available, otherwise CPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"🚀 Using GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"🐌 Using CPU (this will be slower)\")\n",
        "    print(\"💡 Tip: Consider using a machine with GPU for faster inference\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 5: Run Solar Wind Speed Forecasting (Easy Method)\n",
        "\n",
        "This is the simplest way to run inference. The `run_inference` function handles everything for you and will show wind speed predictions vs ground truth!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔬 Starting solar wind speed forecasting inference...\n",
            "Loading model from ./assets/solar_wind_weights.pth\n",
            "Initializing HelioSpectformer1D.\n",
            "Loading pretrained model from ../../data/Surya-1.0/surya.366m.v1.pt.\n",
            "Applying PEFT LoRA with configuration: {'r': 64, 'lora_alpha': 32, 'target_modules': ['q_proj', 'v_proj', 'k_proj', 'out_proj', 'fc1', 'fc2'], 'lora_dropout': 0.1, 'bias': 'none'}\n",
            "trainable params: 8,192,000 || all params: 367,501,313 || trainable%: 2.23%\n",
            "Timedelta 4 days\n",
            "Scalers are not a list of torch tensors, float, int or np.ndarray. What are you feeding in?\n",
            "Dataset size: 3\n",
            "Running inference on 3 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/.venv/lib64/python3.11/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference on 0th sample\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/.venv/lib64/python3.11/site-packages/torch/amp/autocast_mode.py:283: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
            "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
            "  warnings.warn(error_message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==========================================================================================\n",
            "Time Input           | Time Target          | Prediction (km/s)    | Ground Truth (km/s) \n",
            "------------------------------------------------------------------------------------------\n",
            "2011-01-20T01:00     | 2011-01-20T02:00     | 393.63               | 344.00              \n",
            "==========================================================================================\n",
            "Running inference on 1th sample\n",
            "\n",
            "==========================================================================================\n",
            "Time Input           | Time Target          | Prediction (km/s)    | Ground Truth (km/s) \n",
            "------------------------------------------------------------------------------------------\n",
            "2019-01-23T02:00     | 2019-01-23T03:00     | 391.95               | 433.00              \n",
            "==========================================================================================\n",
            "Running inference on 2th sample\n",
            "\n",
            "==========================================================================================\n",
            "Time Input           | Time Target          | Prediction (km/s)    | Ground Truth (km/s) \n",
            "------------------------------------------------------------------------------------------\n",
            "2011-01-20T02:00     | 2011-01-20T03:00     | 383.07               | 351.00              \n",
            "==========================================================================================\n",
            "\n",
            "==========================================================================================\n",
            "SUMMARY STATISTICS\n",
            "==========================================================================================\n",
            "Metric                    | Value               \n",
            "------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error       | 40.9170             \n",
            "Root Mean Square Error    | 41.5408             \n",
            "R² Score                  | -0.0569             \n",
            "Number of Samples         | 3                   \n",
            "==========================================================================================\n",
            "🎉 Solar wind speed forecasting completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Parameters for inference\n",
        "data_type = \"test\"  # or \"valid\" - which dataset to use\n",
        "num_samples = 3  # Number of samples to process and analyze\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(\"🔬 Starting solar wind speed forecasting inference...\")\n",
        "# Run the complete inference pipeline\n",
        "try:\n",
        "    run_inference(\n",
        "        config=config,\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        output_dir=output_dir,\n",
        "        device=device,\n",
        "        data_type=data_type,\n",
        "        num_samples=num_samples,\n",
        "        device_type=device_type\n",
        "    )\n",
        "    print(\"🎉 Solar wind speed forecasting completed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error during inference: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Understanding the Results 📊\n",
        "\n",
        "### What you're seeing:\n",
        "- **Time Input**: The timestamp of the input solar observations\n",
        "- **Time Target**: The timestamp for which we're making the wind speed prediction\n",
        "- **Prediction (km/s)**: The model's predicted solar wind speed in kilometers per second\n",
        "- **Ground Truth (km/s)**: The actual observed wind speed\n",
        "\n",
        "### Key Metrics Explained:\n",
        "1. **Mean Absolute Error (MAE)**: Average absolute difference between predictions and actual values (lower is better)\n",
        "2. **Root Mean Square Error (RMSE)**: Square root of average squared differences (penalizes larger errors more)\n",
        "3. **R² Score**: Coefficient of determination (closer to 1.0 means better predictions, can be negative for very poor models)\n",
        "\n",
        "### Tips for interpretation:\n",
        "1. **Good predictions**: Predicted values close to ground truth values\n",
        "2. **Time difference**: Shows how far ahead the model is forecasting (typically 4 days)\n",
        "3. **Wind speed range**: Typical solar wind speeds are 250-800 km/s\n",
        "4. **Solar storms**: Very high speeds (>600 km/s) often indicate coronal mass ejections\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary 🎯\n",
        "\n",
        "Congratulations! You've successfully run solar wind speed forecasting using the Surya model. \n",
        "\n",
        "### What you accomplished:\n",
        "✅ Downloaded pre-trained model weights  \n",
        "✅ Loaded and configured the regression model  \n",
        "✅ Ran inference on solar data  \n",
        "✅ Generated wind speed predictions with timestamps  \n",
        "✅ Compared predictions with ground truth measurements  \n",
        "✅ Calculated regression metrics (MAE, RMSE, R²)  \n",
        "\n",
        "### Understanding Solar Wind Forecasting:\n",
        "- **Regression Task**: Predicts continuous wind speed values (not binary yes/no)\n",
        "- **4-Day Forecast**: Uses current solar observations to predict wind speed 4 days ahead\n",
        "- **Practical Applications**: Space weather forecasting, satellite protection, power grid management\n",
        "- **Challenges**: Solar wind is inherently chaotic and difficult to predict with perfect accuracy\n",
        "\n",
        "Happy solar wind forecasting! 🌞💨🛰️✨\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
